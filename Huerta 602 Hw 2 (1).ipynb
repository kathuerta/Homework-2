{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mglearn in c:\\users\\kathu\\anaconda3\\lib\\site-packages (0.1.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from mglearn) (0.23.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from mglearn) (2.3.0)\n",
      "Requirement already satisfied: cycler in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from mglearn) (0.10.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from mglearn) (2.2.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from mglearn) (5.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from mglearn) (1.14.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from mglearn) (0.19.1)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from pandas->mglearn) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from pandas->mglearn) (2.7.3)\n",
      "Requirement already satisfied: six in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from cycler->mglearn) (1.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (2.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from matplotlib->mglearn) (1.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kathu\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->mglearn) (39.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Installing Packages I may need\n",
    "import numpy as np \n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sys\n",
    "!{sys.executable} -m pip install mglearn\n",
    "import mglearn\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (506, 13)\n",
      "Feature names:\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore Boston Dataset\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(\"Data shape: {}\".format(boston.data.shape))\n",
    "print(\"Feature names:\\n{}\".format(boston.feature_names))\n",
    "\n",
    "type(boston)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \"Boston House Prices dataset\\n===========================\\n\\nNotes\\n------\\nData Set Characteristics:  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive\\n    \\n    :Median Value (attribute 14) is usually the target\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttp://archive.ics.uci.edu/ml/datasets/Housing\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n**References**\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\\n\"}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 13 measurements as input features - Crime rate, proximity to the Charles River, highway accessibility, and more\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:(506, 104)\n"
     ]
    }
   ],
   "source": [
    "# Load derived dataset\n",
    "\n",
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "print(\"X.shape:{}\".format(X.shape))\n",
    "\n",
    "# The resulting 104 features are derived from the 13 features with 91 possible combinations of two features within those (Muller, page 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:0.95\n",
      "Test set score:0.61\n"
     ]
    }
   ],
   "source": [
    "# Split dataset and split into training and test set to build linear reg model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(\"Training set score:{:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Test set score:{:.2f}\".format(lr.score(X_test, y_test)))\n",
    "# training set predicts accurately but the test set is not great - overfitting because there is a big difference between the two scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:0.89\n",
      "Test set score:0.75\n",
      "Training set score:0.79\n",
      "Test set score:0.64\n",
      "Training set score:0.93\n",
      "Test set score:0.77\n"
     ]
    }
   ],
   "source": [
    "# Use ridge regression to add further constraint for regularization\n",
    "\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "print(\"Training set score:{:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Test set score:{:.2f}\".format(ridge.score(X_test, y_test)))\n",
    "\n",
    "#Training set score with ridge is now lower and the test score higher. \n",
    "# Try increasing alpha to maybe help generalization\n",
    "\n",
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "print(\"Training set score:{:.2f}\".format(ridge10.score(X_train, y_train)))\n",
    "print(\"Test set score:{:.2f}\".format(ridge10.score(X_test, y_test)))\n",
    "\n",
    "# Decrease alpha to see how less restricted coefficients affect the model\n",
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "print(\"Training set score:{:.2f}\".format(ridge01.score(X_train, y_train)))\n",
    "print(\"Test set score:{:.2f}\".format(ridge01.score(X_test, y_test)))\n",
    "# Alpha = 0.1 looks like it works well, but there is such a big difference in the score values \n",
    "# which means there is probably overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:0.29\n",
      "Test set score:0.21\n",
      "Number of features used:4\n"
     ]
    }
   ],
   "source": [
    "# Try Lasso (L1 regularization - setting some coeffs = 0)\n",
    "\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "print(\"Training set score:{:.2f}\".format(lasso.score(X_train,y_train)))\n",
    "print(\"Test set score:{:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "print(\"Number of features used:{}\".format(np.sum(lasso.coef_ !=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:0.90\n",
      "Test set score:0.77\n",
      "Number of features used:33\n",
      "Training set score:0.95\n",
      "Test set score:0.64\n",
      "Number of features used:94\n"
     ]
    }
   ],
   "source": [
    "# Underfitting because values are close and overall bad score for Lasso, decrease alpha which should increase number of features used\n",
    "\n",
    "lasso001 = Lasso(alpha = 0.01, max_iter = 100000).fit(X_train, y_train)\n",
    "print(\"Training set score:{:.2f}\".format(lasso001.score(X_train, y_train)))\n",
    "print(\"Test set score:{:.2f}\".format(lasso001.score(X_test, y_test)))\n",
    "print(\"Number of features used:{}\".format(np.sum(lasso001.coef_ !=0)))\n",
    "\n",
    "# Allowed to fit more complex model, performance a little better than Ridge, and keeping the features at 33, the model is simpler to understand\n",
    "# Decrease alpha even more to see what happens\n",
    "\n",
    "lasso00001 = Lasso(alpha = 0.0001, max_iter = 100000).fit(X_train, y_train)\n",
    "print(\"Training set score:{:.2f}\".format(lasso00001.score(X_train, y_train)))\n",
    "print(\"Test set score:{:.2f}\".format(lasso00001.score(X_test, y_test)))\n",
    "print(\"Number of features used:{}\".format(np.sum(lasso00001.coef_ !=0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:0.33\n",
      "Test set score:0.22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "enet = ElasticNet().fit(X_train, y_train)\n",
    "print(\"Training set score:{:.2f}\".format(enet.score(X_train,y_train)))\n",
    "print(\"Test set score:{:.2f}\".format(enet.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:0.86\n",
      "Test set score:0.72\n"
     ]
    }
   ],
   "source": [
    "enet001= ElasticNet(alpha = 0.01, l1_ratio = 0.5, max_iter=10000, random_state=0).fit(X_train, y_train)\n",
    "print(\"Training set score:{:.2f}\".format(enet001.score(X_train, y_train)))\n",
    "print(\"Test set score:{:.2f}\".format(enet001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:0.92\n",
      "Test set score:0.78\n"
     ]
    }
   ],
   "source": [
    "enet0001= ElasticNet(alpha = 0.001, l1_ratio = 0.5, max_iter=10000, random_state=0).fit(X_train, y_train)\n",
    "print(\"Training set score:{:.2f}\".format(enet0001.score(X_train, y_train)))\n",
    "print(\"Test set score:{:.2f}\".format(enet0001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:0.94\n",
      "Test set score:0.73\n"
     ]
    }
   ],
   "source": [
    "enet00001= ElasticNet(alpha = 0.0001, l1_ratio = 0.5, max_iter=100000, random_state=0).fit(X_train, y_train)\n",
    "print(\"Training set score:{:.2f}\".format(enet00001.score(X_train, y_train)))\n",
    "print(\"Test set score:{:.2f}\".format(enet00001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, random_state=0)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(),\n",
    "    Ridge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'polynomialfeatures__degree': [1,2,3],\n",
    "             'ridge__alpha':[0.001, 0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('polynomialfeatures', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'polynomialfeatures__degree': [1, 2, 3], 'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe, param_grid = param_grid, cv = 5, n_jobs = -1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAENCAYAAADNMlZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFKhJREFUeJzt3X20ZXV93/H3h2EQhBmMDbrIQB3KQrKSIIID8lQqtCoQHmKsVkUTXUYk9QFjqpGVrkq00WqVuNIUKxpsNDz4FBMSrVYNlqKAzIyM4gwkFiGMmCJSmOFBGYZv/zh7hnMv9zJnz5x9z9kz79daZ5279zn3nA8bmM/89v7tvVNVSJKk6bbbpANIkqRts7AlSeoBC1uSpB6wsCVJ6gELW5KkHrCwJUnqAQv7CSQ5JcktSb6f5B2TzjOtklyS5K4kN006yzRLcmCSq5KsS/K9JOdNOtM0SrJnkm8lWdNspz+YdKZpl2RRkm8n+ZtJZ5lWSW5L8t0kNyZZOek82yOehz23JIuAvwOeD6wHbgBeXlVrJxpsCiU5Ebgf+ERV/cqk80yrJPsD+1fV6iRLgFXAr/nf1ExJAuxdVfcnWQxcA5xXVddNONrUSvJWYAWwtKpOn3SeaZTkNmBFVd096SzbyxH2/I4Gvl9Vt1bVw8AVwFkTzjSVqupq4J5J55h2VfWjqlrd/LwRWAcsm2yq6VMD9zeLi5uHI4t5JDkA+FXgY5POom5Z2PNbBtwxtLwe/3DVmCRZDhwBXD/ZJNOp2cV7I3AX8JWqcjvN70PA24FHJx1kyhXwP5OsSnLOpMNsDwt7fpljnX/L1w5Lsg/wOeAtVbVh0nmmUVVtrqpnAwcARyfxUMsckpwO3FVVqyadpQeOr6ojgVOBNzSH8nrFwp7feuDAoeUDgDsnlEU7ieaY7OeAS6vqLyadZ9pV1b3A14FTJhxlWh0PnNkcn70CODnJn0820nSqqjub57uAzzM47NkrFvb8bgAOSXJQkj2AlwFXTjiTeqyZTPWnwLqqunDSeaZVkv2SPKX5eS/gXwE3TzbVdKqq86vqgKpazuDPqL+tqldOONbUSbJ3M9GTJHsDLwB6d1aLhT2PqnoEeCPwZQaTgz5dVd+bbKrplORy4Frg0CTrk7x20pmm1PHAqxiMgm5sHqdNOtQU2h+4Ksl3GPzF+StV5elK2hFPB65Jsgb4FvCFqvrShDO15mldkiT1gCNsSZJ6wMKWJKkHLGxJknrAwpYkqQcsbEmSesDCHkFfL2O30NxOo3E7jc5tNRq30+j6vK0s7NH09l/wAnM7jcbtNDq31WjcTqPr7baysCVJ6oGpunDK0qfuXk9btsekYzzOhnseYelTd590jKnndhqN22l0bqvRTON22jyl48GN92xiyVMXTzrGDLfd9MDdVbXftt43Vf+Gn7ZsDz7wl4dMOoYkaQdtfHSvSUfojd945vW3j/K+6fwrkCRJmsHCliSpByxsSZJ6wMKWJKkHLGxJknrAwpYkqQcsbEmSesDCliSpByxsSZJ6wMKWJKkHLGxJknrAwpYkqQcsbEmSesDCliSpByxsSZJ6wMKWJKkHLGxJknrAwpYkqQcsbEmSesDCliSpByxsSZJ6wMKWJKkHLGxJknrAwpYkqQcsbEmSesDCliSpByxsSZJ6wMKWJKkHLGxJknrAwpYkqQcsbEmSeqDzwk5ySpJbknw/yTu6/j5JknZGnRZ2kkXAfwVOBX4JeHmSX+ryOyVJ2hl1PcI+Gvh+Vd1aVQ8DVwBndfydkiTtdLou7GXAHUPL65t1kiSpha4LO3OsqxlvSM5JsjLJyg33PNJxHEmS+qnrwl4PHDi0fABw5/AbquriqlpRVSuWPnX3juNIktRPXRf2DcAhSQ5KsgfwMuDKjr9TkqSdTqdD2qp6JMkbgS8Di4BLqup7XX6nJEk7o873QVfVF4Evdv09kiTtzLzSmSRJPdCqsJPsleTQrsJIkqS5jVzYSc4AbgS+1Cw/O4kTyCRJWgBtRtgXMLhy2b0AVXUjsHz8kSRJ0mxtCvuRqrqvsySSJGlebWaJ35TkFcCiJIcAbwa+2U0sSZI0rM0I+03ALwM/Ay4D7gPe0kUoSZI008gj7Kp6EPj9JO+pqgc6zCRJkmZpM0v8uCRrgXXN8uFJLuosmSRJ2qrNLvE/Al4I/ASgqtYAJ3YRSpIkzdTqwilVdcesVZvHmEWSJM2jzSzxO5IcB1Rz56030+welyRJ3Wozwj4XeAOwjMF9rp/dLEuSpI6NNMJOsgh4VVWd3XEeSZI0h5FG2FW1GTir4yySJGkebY5hfyPJnwCfAraeh11Vq8eeSpIkzdCmsI9rnt81tK6Ak8cXR5IkzaXNlc5O6jKIJEma38iFneStc6y+D1jV3GpTkiR1pM1pXSsYnNq1rHmcAzwP+GiSt48/miRJ2qLNMex/AhxZVfcDJHkn8FkGlyddBbx//PEkSRK0G2H/U+DhoeVNwDOq6iEGt9yUJEkdaTPCvgy4LslfNctnAJcn2RtYO/ZkkiRpqzazxN+d5IvACUCAc6tqZfOyV0CTJKlDre7WBewFbKiqDwG3Jzmog0ySJGmWkQu7mWT2e8D5zarFwJ93EUqSJM3UZoT9IuBMmsuSVtWdwJIuQkmSpJnaFPbDVVUMLkdKM9lMkiQtgDaF/ekkHwGekuR1wFeBj3YTS5IkDWszS/wDSZ4PbAAOBf5DVX2ls2SSJGmrNudh0xS0JS1J0gLbZmEn2Uhz3HouVbV0rIkkSdLjbLOwq2oJQJJ3Af8IfJLBhVPOZsyzxBfxKEt3++k4P3KntJlMOkJv7JlNk47QC7+w6MFJR+iNgxbvM+kIvfDgo/dOOsJOp82ksxdW1UVVtbGqNlTVh4EXdxVMkiQ9pk1hb05ydpJFSXZLcjawuatgkiTpMW0K+xXAS4H/2zxe0qyTJEkda3Na123AWfO9nuT8qnrvOEJJkqSZ2t7844m8ZIyfJUmShoyzsJ26LElSR8ZZ2POeqy1JknaMI2xJknpgnIX96TF+liRJGuKkM0mSesBd4pIk9YCTziRJ6gFH2JIk9cA4C/szY/wsSZI0ZOTCTvL+JEuTLE7ytSR3J3nllter6j3dRJQkSW1G2C+oqg3A6cB64JnA2zpJJUmSZmhT2Iub59OAy6vqng7ySJKkOYx8ty7gr5PcDDwE/Nsk+wE/7SaWJEkaNvIIu6reARwLrKiqTcCDPMHtNiVJ0vi0mXT2ZOANwIebVb8ArOgilCRJmqnNMeyPAw8DxzXL64H/OPZEkiTpcdoU9sFV9X5gE0BVPYQXS5EkaUG0KeyHk+xFcwnSJAcDP+sklSRJmqHNLPF3Al8CDkxyKXA88OouQkmSpJlGKuwkAW4Gfh04hsGu8POq6u4Os0mSpMZIhV1VleQvq+o5wBc6ziRJkmZpcwz7uiRHdZZEkiTNq80x7JOA1ye5HXiAwW7xqqpndZJMkiRt1aawT+0shSRJekJtCrs6SyFJkp5Qm8L+AoPSDrAncBBwC/DLHeSSJElDRi7sqjpseDnJkcDrx55IkiQ9TptZ4jNU1WrAWeOSJC2AkUfYSd46tLgbcCTw4238ziXA6cBdVfUr25VQkiS1GmEvGXo8icEx7W3dD/u/A6dsVzJJkrRVm0lna6vqM8MrkrwE+Mw876eqrk6yfPuiSZKkLdqMsM8fcV0rSc5JsjLJynvv2byjHydJ0k5pmyPsJKcCpwHLkvzx0EtLgUd2NEBVXQxcDHDoYXt6rrckSXMYZZf4ncBK4Exg1dD6jcDvdBFKkiTNtM3Crqo1wJokl1XVpgXIJEmSZmlzDHt5ks8mWZvk1i2PJ/qFJJcD1wKHJlmf5LU7lFaSpF1Um1niHwfeCfwRgzt3vYbBZUrnVVUv3/5okiRpizYj7L2q6mtAqur2qroAOLmbWJIkaVibEfZPk+wG/H2SNwI/BJ7WTSxJkjSszQj7LcCTgTcDzwFeCfxmF6EkSdJMbe7WdQNAkqqq13QXSZIkzTbyCDvJsUnWAuua5cOTXNRZMkmStFWbXeIfAl4I/AS2np99YhehJEnSTK3uh11Vd8xa5cW/JUlaAG1mid+R5DigkuzBYPLZum5iSZKkYW1G2OcCbwCWAeuBZzfLkiSpY6Pcret9VfV7wElVdfYCZJIkSbOMMsI+LclixnDva0mStH1GOYb9JeBuYO8kGxhcP7y2PFfV0g7zSZIkRhhhV9Xbqmpf4AtVtbSqlgw/L0BGSZJ2eSNPOquqs7oMIkmS5jfKpLONDHaBw2O303SXuCRJC2ibhV1VSxYiiCRJml+bC6cAkORpwJ5blqvqH8aaSJIkPU6bm3+cmeTvgR8A/wu4DfgfHeWSJElD2lzp7N3AMcDfVdVBwL8EvtFJKkmSNEObwt5UVT8BdkuyW1VdxeDypJIkqWNtjmHfm2Qf4Grg0iR3AY90E0uSJA1rM8I+C3gI+B0GVz/7P8AZXYSSJEkzjTzCrqoHhhb/rIMskiRpHtscYSe5pnnemGTD7OfuI0qSpFEunHJC8+wFVCRJmpBWF05J8nPAgcO/V1Wrxx1KkiTNNHJhJ3k38GrgVuDRZnUBJ48/liRJGtZmhP1S4OCqerirMJIkaW5tTuu6CXhKV0EkSdL82oyw3wt8O8lNwM+2rKyqM8eeSpIkzdCmsP8MeB/wXR47hi1JkhZAm8K+u6r+uLMkwI9uejLvPfhZXX6FpDnc/fpjJx2hN479LU+MGcU/PPhzk47QI38y0rvaFPaqJO8FrmTmLnH/65UkqWNtCvuI5vmYoXWe1iVJ0gJocy3xk7oMIkmS5jfyaV1J9k1yYZKVzeODSfbtMpwkSRpocx72JcBGBhdQeSmwAfh4F6EkSdJMbY5hH1xVLx5a/oMkN447kCRJerw2I+yHkpywZSHJ8cBD448kSZJmazPCPhf4RHPcOsA9DG4GIkmSOtZmlvga4PAkS5vlDZ2lkiRJM7S5veaTgBcDy4HdkwBQVe/qJJkkSdqqzS7xvwLuA1YxdKUzSZLUvTaFfUBVndJZEkmSNK82s8S/meSwzpJIkqR5tRlhnwC8OskPGOwSD1BV5e21JEnqWJvCPrWzFJIk6Qm1Kew3AZdU1dquwkiSpLm1OYZ9M/DRJNcnOdcbf0iStHBGLuyq+lhVHQ/8BoNzsb+T5LIk3nZTkqSOtRlhk2QR8IvN425gDfDWJFd0kE2SJDXaXOnsQuBM4GvAe6rqW81L70tySxfhJEnSQJtJZzcB/76qHpzjtaPHlEeSJM1hm4Wd5MjmxxuBX9xyDfEtqmp1Vd3XQTZJktQYZYT9wSd4rYCTx5RFkiTNY5uFXVXOApckacLaTDpbDPw2cGKz6uvAR6pqUwe5JEnSkDaTzj4MLAYuapZf1az7rXGHkiRJM7Up7KOq6vCh5b9NsmbcgSRJ0uO1uXDK5iQHb1lI8s+AzeOPJEmSZmszwn4bcFWSW5vl5cBrxp5IkiQ9TpsR9jeAjwCPNo+PANd2EUqSJM3UZoT9CWAD8O5m+eXAJ4GXjDuUJEmaqU1hHzpr0tlVTjqTJGlhtNkl/u0kx2xZSPJcBrvJJUlSx9oU9nOBbya5LcltDI5f/4sk303ynbl+IcmBSa5Ksi7J95KcN4bMkiTtctrsEj9lOz7/EeB3q2p1kiXAqiRfqaq12/FZkiTtskYu7Kq6ve2HV9WPgB81P29Msg5YBljYkiS10GaX+A5Jshw4Arh+ob5TkqSdRZtd4tstyT7A54C3VNWGWa+dA5wDsCdPXog4kiT1Tucj7OYuX58DLq2qv5j9elVdXFUrqmrFYp7UdRxJknqp08JOEuBPgXVVdWGX3yVJ0s6s6xH28Qxuw3lykhubx2kdf6ckSTudTo9hV9U1QLr8DkmSdgULNktckiRtPwtbkqQesLAlSeoBC1uSpB6wsCVJ6gELW5KkHrCwJUnqAQtbkqQesLAlSeoBC1uSpB6wsCVJ6gELW5KkHrCwJUnqAQtbkqQesLAlSeoBC1uSpB6wsCVJ6gELW5KkHrCwJUnqAQtbkqQesLAlSeoBC1uSpB6wsCVJ6gELW5KkHrCwJUnqAQtbkqQesLAlSeoBC1uSpB6wsCVJ6gELW5KkHrCwJUnqAQtbkqQeSFVNOsNWSX4M3D7pHHP4eeDuSYfoAbfTaNxOo3NbjcbtNLpp3FbPqKr9tvWmqSrsaZVkZVWtmHSOaed2Go3baXRuq9G4nUbX523lLnFJknrAwpYkqQcs7NFcPOkAPeF2Go3baXRuq9G4nUbX223lMWxpiiX5IvCKqrp31voLgPur6gMTynV/Ve2zo++RNLrdJx1A0tySBDi9qh6ddBZJk+cucWmKJFmeZF2Si4DVwOYkP9+89vtJbknyVeDQod85Ksl3klyb5D8nualZv6hZvqF5/fUts+yT5GtJVif5bpKz5njP85JcneTzSdYm+W9Jdht6/Q+TrElyXZKnN+vOSHJ9km8n+eqW9ZKemIUtTZ9DgU9U1RE01yVI8hzgZcARwK8DRw29/+PAuVV1LLB5aP1rgfuq6qjm/a9LclCLHD8FXlRVRwInAR9sRv2zHQ38LnAYcHCTD2Bv4LqqOhy4Gnhds/4a4Jjmn+8K4O0tMkm7LHeJS9Pn9qq6bta6fw58vqoeBEhyZfP8FGBJVX2zed9lwOnNzy8AnpXkXzfL+wKHAD8YMUeA9yQ5EXgUWAY8HfjHWe/7VlXd2uS5HDgB+CzwMPA3zXtWAc9vfj4A+FSS/YE9WuSRdmkWtjR9Hphn/VwzROca8Q6/9qaq+vJ25jgb2A94TlVtSnIbsOcIubYsb6rHZrVu5rE/b/4LcGFVXZnkecAF25lP2qW4S1zqh6uBFyXZK8kS4AyAqvp/wMYkxzTve9nQ73wZ+O0kiwGSPDPJ3i2+c1/grqasTwKeMc/7jk5yUHPs+t8w2OW9rc/9YfPzb7bII+3SHGFLPVBVq5N8CriRwXHt/z308muBjyZ5APg6cF+z/mPAcmB1c+z5x8CvtfjaS4G/TrKy+d6b53nftcB/YnAM+2rg89v43AuAzyT5IXAd0Oa4urTL8jxsqeeS7FNV9zc/vwPYv6rOW6Dvfh7w76rq9G29V9KOcYQt9d+vJjmfwf/PtwOvnmwcSV1whC3tQpIcBnxy1uoDgTtmrftZVT13YVJJGoWFLUlSDzhLXJKkHrCwJUnqAQtbkqQesLAlSeoBC1uSpB74/2VK+ff9l3bSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(grid.cv_results_['mean_test_score'].reshape(3, -1), vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"ridge__alpha\")\n",
    "plt.ylabel(\"polynomialfeatures__degree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:{'polynomialfeatures__degree': 2, 'ridge__alpha': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set score:0.77\n"
     ]
    }
   ],
   "source": [
    "print(\"Test-set score:{:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without poly features:0.63\n"
     ]
    }
   ],
   "source": [
    "# run gridsearch without polynomials\n",
    "\n",
    "param_grid = {'ridge__alpha':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "pipe = make_pipeline(StandardScaler(), Ridge())\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Score without poly features:{:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score is better with polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:{'lasso__alpha': 0.1, 'polynomialfeatures__degree': 2}\n",
      "Test-set score:0.78\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch on lasso\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(),\n",
    "    Lasso())\n",
    "param_grid = {'polynomialfeatures__degree': [1,2,3],\n",
    "             'lasso__alpha':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(pipe, param_grid = param_grid, cv = 5, n_jobs = -1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters:{}\".format(grid.best_params_))\n",
    "print(\"Test-set score:{:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:{'elasticnet__alpha': 0.1, 'polynomialfeatures__degree': 2}\n",
      "Test-set score:0.79\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch on ElasticNet\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(),\n",
    "    ElasticNet())\n",
    "param_grid = {'polynomialfeatures__degree': [1,2,3],\n",
    "             'elasticnet__alpha':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(pipe, param_grid = param_grid, cv = 5, n_jobs = -1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters:{}\".format(grid.best_params_))\n",
    "print(\"Test-set score:{:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
